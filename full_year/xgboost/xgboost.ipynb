{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a0cfe8",
   "metadata": {},
   "source": [
    "# XGBoost or eXtreme Gradient Boosting Method for the Train Delay Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54fdb9a",
   "metadata": {},
   "source": [
    "### First of all, we have to load the data, then take a pre-trained model and fit it to our data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a7ea75",
   "metadata": {},
   "source": [
    "The first step is to have our imports and the logging configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3ededc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:52:22.770748Z",
     "iopub.status.busy": "2025-02-11T14:52:22.770607Z",
     "iopub.status.idle": "2025-02-11T14:52:24.797934Z",
     "shell.execute_reply": "2025-02-11T14:52:24.797583Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(\"/Users/mac/Desktop/train_delay_prediction/utils.py\"))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='xgboost_evaluation.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "logging.info(\"Starting eXtreme Gradient Boosting evaluation script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57462be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "percentage_of_data_usage = 1.0\n",
    "train_months = [1]      # This will be updated dynamically ([1], [1,2], ..., [1,...,11])\n",
    "test_months = [12]      # December is fixed for testing\n",
    "suffix = \"\"             # Suffix to uniquely identify each progressive run (\"_prog_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343181e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:52:24.800170Z",
     "iopub.status.busy": "2025-02-11T14:52:24.799936Z",
     "iopub.status.idle": "2025-02-11T14:52:24.802842Z",
     "shell.execute_reply": "2025-02-11T14:52:24.802574Z"
    }
   },
   "outputs": [],
   "source": [
    "# The ones that perform best:\n",
    "n_estimators = 10\n",
    "max_depth = 7\n",
    "\n",
    "print(f\"Running XGBoost with n_estimators={n_estimators} and max_depth={max_depth}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a10f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combining JSON metrics: 100%|██████████| 13/13 [00:00<00:00, 3072.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combine_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5216af9",
   "metadata": {},
   "source": [
    "Then we have to load the data and split it correctly, in a way that is not biased. This means separating the test and train set in a way that they are independent according to the dates of departure in order to mitigate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd481633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:52:24.804968Z",
     "iopub.status.busy": "2025-02-11T14:52:24.804855Z",
     "iopub.status.idle": "2025-02-11T14:52:26.183467Z",
     "shell.execute_reply": "2025-02-11T14:52:26.181099Z"
    }
   },
   "outputs": [],
   "source": [
    "data = load_full_year_data(percentage_of_data_usage=percentage_of_data_usage, train_months=train_months, test_months=test_months)\n",
    "\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test = data[\"X_test\"]\n",
    "y_test = data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff98f65",
   "metadata": {},
   "source": [
    "Now, we our going to do a multi-output regression, fit the model to our data, and get the predicted delay stored in a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bef234a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T14:52:26.185386Z",
     "iopub.status.busy": "2025-02-11T14:52:26.185251Z",
     "iopub.status.idle": "2025-02-11T15:05:11.993297Z",
     "shell.execute_reply": "2025-02-11T15:05:11.992635Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_models = {}\n",
    "\n",
    "xgb_regressor = MultiOutputRegressor(\n",
    "    XGBRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    ")\n",
    "\n",
    "model_name = \"XGBoost\"\n",
    "trained_model_data = train(xgb_regressor, X_train, y_train, model_name, savemodel=False)\n",
    "trained_models[model_name] = trained_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b0cd38",
   "metadata": {},
   "source": [
    "We are defining some score metrics to measure accuracy and eventually compare our model to the others. We will save all of those metrics in a .npy and in a .json file in order to store them and load them easily when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd2b7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T01:19:54.044960Z",
     "iopub.status.busy": "2025-01-31T01:19:54.044729Z",
     "iopub.status.idle": "2025-01-31T01:19:54.414719Z",
     "shell.execute_reply": "2025-01-31T01:19:54.414320Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.info(f\"Starting evaluation {suffix}\")\n",
    "metrics = evaluate_2_fullyear(trained_model=trained_model_data, X_test=X_test, y_test=y_test, model_name=model_name + suffix)\n",
    "logging.info(f\"Evaluation complete {suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e89dcd8",
   "metadata": {},
   "source": [
    "The next step is having some graphs just to visualize some results. An important graph is the last one, where we get to see which features have the most influence on our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b27cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-11T15:05:11.996828Z",
     "iopub.status.busy": "2025-02-11T15:05:11.996677Z",
     "iopub.status.idle": "2025-02-11T15:05:11.998920Z",
     "shell.execute_reply": "2025-02-11T15:05:11.998658Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate_feature_importance(\n",
    "#     trained_models=trained_models,\n",
    "#     X_test=X_test,\n",
    "#     y_test=y_test,\n",
    "#     top_features_threshold=0.01,\n",
    "#     n_repeats=5\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b935ad3",
   "metadata": {},
   "source": [
    "### We are done with the evaluation of the data and prediction of train delay prediction with this model and will move on to the next one. Feel free to load the results wherever they are needed, check out the other models, or see the comparison of all models in the resutls notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
