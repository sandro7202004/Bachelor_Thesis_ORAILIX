{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf1b7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(\"/Users/mac/Desktop/train_delay_prediction/utils.py\"))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='MLP_evaluation.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    ")\n",
    "logging.info(\"Starting Multilayer Perceptron evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9886ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data_more_features(percentage_of_data_usage=1.0)\n",
    "\n",
    "X_train = data[\"X_train\"]\n",
    "y_train = data[\"y_train\"]\n",
    "X_test = data[\"X_test\"]\n",
    "y_test = data[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d7f0d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.60664579\n",
      "Iteration 2, loss = 0.48203656\n",
      "Iteration 3, loss = 0.45145979\n",
      "Iteration 4, loss = 0.43389531\n",
      "Iteration 5, loss = 0.42123456\n",
      "Iteration 6, loss = 0.41289697\n",
      "Iteration 7, loss = 0.40725684\n",
      "Iteration 8, loss = 0.40238319\n",
      "Iteration 9, loss = 0.39851472\n",
      "Iteration 10, loss = 0.39546168\n",
      "Iteration 11, loss = 0.39321738\n",
      "Iteration 12, loss = 0.39113884\n",
      "Iteration 13, loss = 0.39008144\n",
      "Iteration 14, loss = 0.38652118\n",
      "Iteration 15, loss = 0.38600435\n",
      "Iteration 16, loss = 0.38376752\n",
      "Iteration 17, loss = 0.38273653\n",
      "Iteration 18, loss = 0.38184294\n",
      "Iteration 19, loss = 0.38136447\n",
      "Iteration 20, loss = 0.38007848\n",
      "Iteration 21, loss = 0.37889601\n",
      "Iteration 22, loss = 0.37909774\n",
      "Iteration 23, loss = 0.37779519\n",
      "Iteration 24, loss = 0.37704210\n",
      "Iteration 25, loss = 0.37762814\n",
      "Iteration 26, loss = 0.37614111\n",
      "Iteration 27, loss = 0.37562113\n",
      "Iteration 28, loss = 0.37502837\n",
      "Iteration 29, loss = 0.37451819\n",
      "Iteration 30, loss = 0.37431156\n",
      "Iteration 31, loss = 0.37416945\n",
      "Iteration 32, loss = 0.37299494\n",
      "Iteration 33, loss = 0.37283558\n",
      "Iteration 34, loss = 0.37273860\n",
      "Iteration 35, loss = 0.37240382\n",
      "Iteration 36, loss = 0.37155944\n",
      "Iteration 37, loss = 0.37178152\n",
      "Iteration 38, loss = 0.37167506\n",
      "Iteration 39, loss = 0.37171737\n",
      "Iteration 40, loss = 0.37080382\n",
      "Iteration 41, loss = 0.37090061\n",
      "Iteration 42, loss = 0.37017667\n",
      "Iteration 43, loss = 0.37027177\n",
      "Iteration 44, loss = 0.37026963\n",
      "Iteration 45, loss = 0.37009867\n",
      "Iteration 46, loss = 0.36973492\n",
      "Iteration 47, loss = 0.36974868\n",
      "Iteration 48, loss = 0.36946499\n",
      "Iteration 49, loss = 0.36884006\n",
      "Iteration 50, loss = 0.36941699\n",
      "Iteration 51, loss = 0.36960487\n",
      "Iteration 52, loss = 0.36830502\n",
      "Iteration 53, loss = 0.36851312\n",
      "Iteration 54, loss = 0.36863081\n",
      "Iteration 55, loss = 0.36854622\n",
      "Iteration 56, loss = 0.36889546\n",
      "Iteration 57, loss = 0.36833157\n",
      "Iteration 58, loss = 0.36847867\n",
      "Iteration 59, loss = 0.36800220\n",
      "Iteration 60, loss = 0.36862635\n",
      "Iteration 61, loss = 0.36787771\n",
      "Iteration 62, loss = 0.36801459\n",
      "Iteration 63, loss = 0.36756080\n",
      "Iteration 64, loss = 0.36747586\n",
      "Iteration 65, loss = 0.36696663\n",
      "Iteration 66, loss = 0.36727085\n",
      "Iteration 67, loss = 0.36714501\n",
      "Iteration 68, loss = 0.36694431\n",
      "Iteration 69, loss = 0.36680801\n",
      "Iteration 70, loss = 0.36651769\n",
      "Iteration 71, loss = 0.36756105\n",
      "Iteration 72, loss = 0.36684609\n",
      "Iteration 73, loss = 0.36682698\n",
      "Iteration 74, loss = 0.36666538\n",
      "Iteration 75, loss = 0.36713228\n",
      "Iteration 76, loss = 0.36656580\n",
      "Iteration 77, loss = 0.36689563\n",
      "Iteration 78, loss = 0.36623065\n",
      "Iteration 79, loss = 0.36699868\n",
      "Iteration 80, loss = 0.36612457\n",
      "Iteration 81, loss = 0.36665056\n",
      "Iteration 82, loss = 0.36650166\n",
      "Iteration 83, loss = 0.36617368\n",
      "Iteration 84, loss = 0.36677024\n",
      "Iteration 85, loss = 0.36639559\n",
      "Iteration 86, loss = 0.36613985\n",
      "Iteration 87, loss = 0.36647614\n",
      "Iteration 88, loss = 0.36654008\n",
      "Iteration 89, loss = 0.36648230\n",
      "Iteration 90, loss = 0.36665027\n",
      "Iteration 91, loss = 0.36647412\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.58467552\n",
      "Iteration 2, loss = 0.48188672\n",
      "Iteration 3, loss = 0.46233428\n",
      "Iteration 4, loss = 0.45019483\n",
      "Iteration 5, loss = 0.44186765\n",
      "Iteration 6, loss = 0.43485509\n",
      "Iteration 7, loss = 0.42985000\n",
      "Iteration 8, loss = 0.42525430\n",
      "Iteration 9, loss = 0.42190012\n",
      "Iteration 10, loss = 0.41902749\n",
      "Iteration 11, loss = 0.41679196\n",
      "Iteration 12, loss = 0.41426027\n",
      "Iteration 13, loss = 0.41265377\n",
      "Iteration 14, loss = 0.41082218\n",
      "Iteration 15, loss = 0.40955391\n",
      "Iteration 16, loss = 0.40787063\n",
      "Iteration 17, loss = 0.40680340\n",
      "Iteration 18, loss = 0.40508769\n",
      "Iteration 19, loss = 0.40445709\n",
      "Iteration 20, loss = 0.40340181\n",
      "Iteration 21, loss = 0.40286664\n",
      "Iteration 22, loss = 0.40202596\n",
      "Iteration 23, loss = 0.40151271\n",
      "Iteration 24, loss = 0.40080654\n",
      "Iteration 25, loss = 0.40018501\n",
      "Iteration 26, loss = 0.39911964\n",
      "Iteration 27, loss = 0.39905230\n",
      "Iteration 28, loss = 0.39860975\n",
      "Iteration 29, loss = 0.39799169\n",
      "Iteration 30, loss = 0.39767274\n",
      "Iteration 31, loss = 0.39706595\n",
      "Iteration 32, loss = 0.39668898\n",
      "Iteration 33, loss = 0.39654730\n",
      "Iteration 34, loss = 0.39604746\n",
      "Iteration 35, loss = 0.39568639\n",
      "Iteration 36, loss = 0.39532169\n",
      "Iteration 37, loss = 0.39530589\n",
      "Iteration 38, loss = 0.39495983\n",
      "Iteration 39, loss = 0.39459798\n",
      "Iteration 40, loss = 0.39439210\n",
      "Iteration 41, loss = 0.39409951\n",
      "Iteration 42, loss = 0.39386170\n",
      "Iteration 43, loss = 0.39366646\n",
      "Iteration 44, loss = 0.39330735\n",
      "Iteration 45, loss = 0.39351724\n",
      "Iteration 46, loss = 0.39308755\n",
      "Iteration 47, loss = 0.39320120\n",
      "Iteration 48, loss = 0.39287045\n",
      "Iteration 49, loss = 0.39252142\n",
      "Iteration 50, loss = 0.39245128\n",
      "Iteration 51, loss = 0.39221819\n",
      "Iteration 52, loss = 0.39215573\n",
      "Iteration 53, loss = 0.39217277\n",
      "Iteration 54, loss = 0.39218144\n",
      "Iteration 55, loss = 0.39165558\n",
      "Iteration 56, loss = 0.39154988\n",
      "Iteration 57, loss = 0.39188943\n",
      "Iteration 58, loss = 0.39191452\n",
      "Iteration 59, loss = 0.39126561\n",
      "Iteration 60, loss = 0.39161773\n",
      "Iteration 61, loss = 0.39161851\n",
      "Iteration 62, loss = 0.39129485\n",
      "Iteration 63, loss = 0.39112396\n",
      "Iteration 64, loss = 0.39117466\n",
      "Iteration 65, loss = 0.39083386\n",
      "Iteration 66, loss = 0.39114091\n",
      "Iteration 67, loss = 0.39100013\n",
      "Iteration 68, loss = 0.39089206\n",
      "Iteration 69, loss = 0.39093579\n",
      "Iteration 70, loss = 0.39079305\n",
      "Iteration 71, loss = 0.39062669\n",
      "Iteration 72, loss = 0.39088890\n",
      "Iteration 73, loss = 0.39089013\n",
      "Iteration 74, loss = 0.39077959\n",
      "Iteration 75, loss = 0.39066052\n",
      "Iteration 76, loss = 0.39080729\n",
      "Iteration 77, loss = 0.39072916\n",
      "Iteration 78, loss = 0.39078477\n",
      "Iteration 79, loss = 0.39058913\n",
      "Iteration 80, loss = 0.39050659\n",
      "Iteration 81, loss = 0.39068084\n",
      "Iteration 82, loss = 0.39067977\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "architectures = [\n",
    "    # {\"name\": \"1\", \"hidden_layer_sizes\": (1,)},\n",
    "    # {\"name\": \"10\", \"hidden_layer_sizes\": (10,)},\n",
    "    # {\"name\": \"50\", \"hidden_layer_sizes\": (50,)},\n",
    "    # {\"name\": \"20-20\", \"hidden_layer_sizes\": (20, 20)},\n",
    "    {\"name\": \"256-256\", \"hidden_layer_sizes\": (256, 256)},\n",
    "    # {\"name\": \"10-10-10\", \"hidden_layer_sizes\": (10, 10, 10)},\n",
    "    {\"name\": \"50-50-50\", \"hidden_layer_sizes\": (50, 50, 50)},\n",
    "    # {\"name\": \"256-512-256-64-8\", \"hidden_layer_sizes\": (256, 512, 256, 64, 8)},\n",
    "]\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for arch in architectures:\n",
    "    model_name = arch[\"name\"]\n",
    "    model = MLPRegressor(\n",
    "        hidden_layer_sizes=arch[\"hidden_layer_sizes\"],\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        max_iter=200,\n",
    "        random_state=42,\n",
    "        n_iter_no_change=10,\n",
    "    )\n",
    "\n",
    "    trained_model_data = train(model, X_train, y_train, model_name, savemodel=False)\n",
    "    trained_models[model_name] = trained_model_data\n",
    "\n",
    "    metrics = evaluate_2(\n",
    "        trained_model=trained_model_data,\n",
    "        X_test=X_test,\n",
    "        y_test=y_test,\n",
    "        model_name=model_name,\n",
    "    )\n",
    "\n",
    "# combine_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f5afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_all_pkl_contents()\n",
    "# convert_pkl_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56d6bbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating feature importance: 100%|██████████| 2/2 [49:48<00:00, 1494.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# visualize_network_architecture(architectures, X_train, y_train)\n",
    "\n",
    "calculate_feature_importance(\n",
    "    trained_models=trained_models, \n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    feature_mapping=data[\"columns_scheme\"][\"x\"],\n",
    "    top_features_threshold=0.1,\n",
    "    n_repeats=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfac20",
   "metadata": {},
   "source": [
    "## Run with new target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dfcdd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_newtarget = load_data_newtarget(percentage_of_data_usage=0.01)\n",
    "\n",
    "# X_train_newtarget = data_newtarget[\"X_train\"]\n",
    "# y_train_newtarget = data_newtarget[\"y_train\"]\n",
    "# X_test_newtarget = data_newtarget[\"X_test\"]\n",
    "# y_test_newtarget = data_newtarget[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef9ed01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_models_newtarget = {}\n",
    "\n",
    "# for arch in architectures:\n",
    "#     model_name = arch[\"name\"]\n",
    "#     model_newtarget = MLPRegressor(\n",
    "#         hidden_layer_sizes=arch[\"hidden_layer_sizes\"],\n",
    "#         activation=\"relu\",\n",
    "#         solver=\"adam\",\n",
    "#         max_iter=200,\n",
    "#         random_state=42,\n",
    "#         n_iter_no_change=10,\n",
    "#     )\n",
    "\n",
    "#     trained_model_data_newtarget = train(model_newtarget, X_train_newtarget, y_train_newtarget, model_name, savemodel=False)\n",
    "#     trained_models_newtarget[model_name] = trained_model_data_newtarget\n",
    "\n",
    "#     metrics_newtarget = evaluate_2_newtarget(\n",
    "#         trained_model=trained_model_data_newtarget,\n",
    "#         X_test=X_test_newtarget,\n",
    "#         y_test=y_test_newtarget,\n",
    "#         model_name=model_name,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f465e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"MLP evaluation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
